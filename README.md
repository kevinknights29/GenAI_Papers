# GenAI_Papers

This project contains a list of interesting research papers in the field of GenAI

**Topics**

1. [Overview](#overview)
2. [Goals](#goals)
3. [Scope and Context](#scope-and-context)
4. [Research Papers](#research-papers)
5. [Learning Logs](#learning-logs)

---


## Overview

## Goals

## Scope and Context

## Research Papers

NOTE: not in a particular order.

1. [Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts](https://browse.arxiv.org/pdf/2307.11661.pdf)
2. [EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention](https://arxiv.org/pdf/2305.07027.pdf)
3. [Key-Locked Rank One Editing for Text-to-Image Personalization](https://browse.arxiv.org/pdf/2305.01644.pdf)
4. [ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders](https://arxiv.org/pdf/2308.01317.pdf)
5. [Simple and Controllable Music Generation](https://arxiv.org/pdf/2306.05284.pdf)
6. [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/pdf/2112.10752.pdf)
7. [All are Worth Words: A ViT Backbone for Diffusion Models](https://arxiv.org/pdf/2209.12152.pdf)
8. [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
9. [A Mathematical View of Attention Models in Deep Learning](https://people.tamu.edu/~sji/classes/attn.pdf)
10. [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
11. [Large Language Models and the Reverse Turing Test](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10177005/pdf/nihms-1876424.pdf)
12. [ESTIMATING THE CARBON FOOTPRINT OF BLOOM, A 176B PARAMETER LANGUAGE MODEL](https://arxiv.org/pdf/2211.02001.pdf)
13. [LaMDA: Language Models for Dialog Applications](https://arxiv.org/pdf/2201.08239.pdf)
14. [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/pdf/2305.15334.pdf)
15. [Foundation Models for Decision Making Problems, Methods, and Opportunities](https://arxiv.org/pdf/2303.04129.pdf)
16. [CONTINUAL PRE-TRAINING OF LANGUAGE MODELS](https://arxiv.org/pdf/2302.03241.pdf)
17. [How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources](https://arxiv.org/pdf/2306.04751.pdf)
16. [ALPAGASUS: TRAINING A BETTER ALPACA WITH FEWER DATA](https://arxiv.org/pdf/2307.08701.pdf)
17. [Ethical and social risks of harm from Language Models](https://arxiv.org/pdf/2112.04359.pdf)
18. [Holistic Evaluation of Language Models](https://arxiv.org/pdf/2211.09110.pdf)
19. [On the Risk of Misinformation Pollution with Large Language Models](https://arxiv.org/pdf/2305.13661.pdf)
20. [The Capacity for Moral Self-Correction in Large Language Models](https://arxiv.org/pdf/2302.07459.pdf)
21. [HONEST: Measuring Hurtful Sentence Completion in Language Models](https://aclanthology.org/2021.naacl-main.191.pdf)
22. [REACT: SYNERGIZING REASONING AND ACTING INLANGUAGE MODELS](https://arxiv.org/pdf/2210.03629.pdf)
23. [EFFICIENTLY SCALING TRANSFORMER INFERENCE](https://arxiv.org/pdf/2211.05102.pdf)
24. [Hungry Hungry Hippos: Towards Language Modeling with State Space Models](https://arxiv.org/pdf/2212.14052.pdf)
25. [PROMPTBREEDER: SELF-REFERENTIAL SELF-IMPROVEMENT VIA PROMPT EVOLUTION](https://arxiv.org/pdf/2309.16797.pdf)
26. [Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/pdf/2309.17453v1.pdf)
27. [Visual Instruction Tuning](https://arxiv.org/pdf/2304.08485.pdf)
28. [Improved Baselines with Visual Instruction Tuning](https://arxiv.org/pdf/2310.03744.pdf)
29. [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290.pdf)
30. [Distil-Whisper: Robust Knowledge Distilation via Large-Scale Pseudo Labelling](https://github.com/huggingface/distil-whisper/blob/main/Distil_Whisper.pdf)
31. [Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms](https://arxiv.org/pdf/2310.10418.pdf)


## Learning Logs

| Date | Learning |
|------|----------|
|      |          |